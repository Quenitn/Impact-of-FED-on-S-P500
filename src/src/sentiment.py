import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from src.config import BERT_MODEL_NAME, CHUNK_SIZE

class SentimentAnalyzer:
    """Analyse le sentiment des textes financiers avec FinBERT."""

    def __init__(self):
        print("ü§ñ Chargement du mod√®le FinBERT...")
        self.tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)
        self.model = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_NAME)
        self.model.eval() # Mode √©valuation (pas d'entra√Ænement)

    def predict_score(self, text: str) -> float:
        """
        D√©coupe le texte en chunks et retourne un score Hawkish agr√©g√©.
        Score = Moyenne(Positif - N√©gatif) sur tous les chunks.
        """
        if not isinstance(text, str) or len(text.strip()) == 0:
            return 0.0

        # Tokenisation sans tronquer au d√©but pour g√©rer manuellement les chunks
        inputs = self.tokenizer(text, return_tensors="pt", truncation=False, padding=False)
        input_ids = inputs["input_ids"][0]

        # D√©coupage en chunks
        chunks = [input_ids[i : i + CHUNK_SIZE] for i in range(0, len(input_ids), CHUNK_SIZE)]
        
        scores = []
        with torch.no_grad():
            for chunk in chunks:
                # Si le chunk est trop petit, on ignore ou on pad (ici simple gestion)
                if len(chunk) > 510: 
                    chunk = chunk[:510] # S√©curit√© pour respecter la limite BERT
                
                outputs = self.model(input_ids=chunk.unsqueeze(0))
                probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].numpy()
                scores.append(probs)

        if not scores:
            return 0.0

        # Moyenne des probabilit√©s [negative, neutral, positive]
        mean_probs = np.mean(scores, axis=0)
        
        # Calcul du score Hawkish (Positive - Negative)
        # FinBERT labels: 0: neutral, 1: positive, 2: negative (ATTENTION : v√©rifier l'ordre sp√©cifique du mod√®le)
        # Pour yiyanghkust/finbert-tone : labels sont ["Neutral", "Positive", "Negative"] g√©n√©ralement
        # Mais v√©rifions l'ordre standard de config:
        # Souvent: 0=Negative, 1=Neutral, 2=Positive OU l'inverse. 
        # Dans ton notebook tu utilisais : labels = ['negative', 'neutral', 'positive']
        # On garde ta logique du notebook :
        negative = mean_probs[0]
        positive = mean_probs[2]
        
        return positive - negative
